{"ast":null,"code":"import axios from 'axios';\nexport default {\n  name: 'AIPrompt',\n  data() {\n    return {\n      modelName: 'GPT 3.5 Turbo',\n      prompt_1: '',\n      prompt_2: '',\n      aiResponse_1: '',\n      aiResponse_2: '',\n      loading_1: false,\n      loading_2: false,\n      prompting_type: \"\",\n      textareaStyle: {\n        height: '200px'\n      },\n      openai_isActive: true,\n      together_isActive: false,\n      ex01_isActive: false,\n      ex02_isActive: false,\n      contentRowStyle: {\n        height: '700px'\n      },\n      promptType_01: '',\n      promptType_02: ''\n    };\n  },\n  methods: {\n    setModel(name) {\n      this.modelName = name;\n      if (name == 'GPT 3.5 Turbo') {\n        this.openai_isActive = !this.openai_isActive;\n        this.together_isActive = false;\n      }\n      if (name == 'llama-2-70b-chat') {\n        this.openai_isActive = false;\n        this.together_isActive = !this.together_isActive;\n      }\n    },\n    ex01_setText() {\n      this.promptType_01 = 'Zero-Shot Prompting';\n      this.promptType_02 = 'Few-Shot Prompting';\n      this.ex01_isActive = !this.ex01_isActive;\n      this.ex02_isActive = false;\n      this.prompt_1 = \"What are the recommended treatments for hypertension?\";\n      this.prompt_2 = \"Question 1: What is the primary function of the heart in the human body?\\n\" + \"Answer 1: The primary function of the heart is to pump blood throughout \" + \"the body, delivering oxygen and nutrients to tissues and removing carbon \" + \"dioxide and other wastes.\\n\\n\" + \"Question 2: Can you explain what causes the common cold?\\n\" + \"Answer 2: The common cold is primarily caused by rhinoviruses. \" + \"It spreads through airborne droplets when an infected person coughs \" + \"or sneezes, or through direct contact with infected surfaces.\\n\\n\" + \"Question 3: What are the typical symptoms of diabetes?\\n\" + \"Answer 3: Typical symptoms of diabetes include increased thirst, \" + \"frequent urination, hunger, fatigue, and blurred vision. \" + \"In some cases, there may also be weight loss despite an increase \" + \"in appetite.\\n\\n\" + \"New Question: What are the recommended treatments for hypertension?\";\n      this.textareaStyle.height = \"400px\";\n    },\n    ex02_setText() {\n      this.promptType_01 = 'Few-Shot Prompting';\n      this.promptType_02 = 'Few-Shot-CoT Prompting';\n      this.ex01_isActive = false;\n      this.ex02_isActive = !this.ex02_isActive;\n      this.prompt_1 = \"Q: Roger has 5 tennis balls. He buys 2 more cans of tennis \" + \"balls. Each can has 3 tennis balls. How many tennis balls does \" + \"he have now?\\n\" + \"A: The answer is 11.\\n\\n\" + \"Q: A juggler can juggle 16 balls. Half of the balls are golf balls, \" + \"and half of the golf balls are blue. How many blue golf balls are there?\\n\" + \"A:\";\n      this.prompt_2 = \"Q: Roger has 5 tennis balls. He buys 2 more cans of tennis \" + \"balls. Each can has 3 tennis balls. How many tennis balls does \" + \"he have now?\\n\" + \"A: Roger started with 5 balls. 2 cans of 3 tennis balls each is 6 \" + \"tennis balls. 5 + 6 = 11. The answer is 11.\\n\\n\" + \"Q: A juggler can juggle 16 balls. Half of the balls are golf balls, \" + \"and half of the golf balls are blue. How many blue golf balls are there?\\n\";\n      \"A:\";\n      this.textareaStyle.height = \"200px\";\n    },\n    async getAIResponse(prompt_text, prompt_type, modelName) {\n      if (modelName == 'GPT 3.5 Turbo') {\n        if (prompt_type == \"few_shot\") {\n          this.loading_2 = true; // Set loading to true when the request starts\n          try {\n            const response = await axios.post('http://localhost:8000/openai/', `prompt=${prompt_text}`, {\n              headers: {\n                'Content-Type': 'application/x-www-form-urlencoded'\n              }\n            });\n            this.aiResponse_2 = response.data.response;\n            this.contentRowStyle.height = 'auto';\n          } catch (error) {\n            console.error(\"There was an error fetching the AI response:\", error);\n            // Handle error (e.g., show error message)\n          } finally {\n            this.loading_2 = false; // Reset loading state once the request is complete\n          }\n        }\n        if (prompt_type == \"zero_shot\") {\n          this.loading_1 = true; // Set loading to true when the request starts\n          try {\n            const response = await axios.post('http://localhost:8000/openai/', `prompt=${prompt_text}`, {\n              headers: {\n                'Content-Type': 'application/x-www-form-urlencoded'\n              }\n            });\n            this.aiResponse_1 = response.data.response;\n            this.contentRowStyle.height = 'auto';\n          } catch (error) {\n            console.error(\"There was an error fetching the AI response:\", error);\n            // Handle error (e.g., show error message)\n          } finally {\n            this.loading_1 = false; // Reset loading state once the request is complete\n          }\n        }\n      } else if (modelName == 'llama-2-70b-chat') {\n        if (prompt_type == \"few_shot\") {\n          this.loading_2 = true; // Set loading to true when the request starts\n          try {\n            const response = await axios.post('http://localhost:8000/together/', `prompt=${prompt_text}`, {\n              headers: {\n                'Content-Type': 'application/x-www-form-urlencoded'\n              }\n            });\n            this.aiResponse_2 = response.data.response;\n            this.contentRowStyle.height = 'auto';\n          } catch (error) {\n            console.error(\"There was an error fetching the AI response:\", error);\n            // Handle error (e.g., show error message)\n          } finally {\n            this.loading_2 = false; // Reset loading state once the request is complete\n          }\n        }\n        if (prompt_type == \"zero_shot\") {\n          this.loading_1 = true; // Set loading to true when the request starts\n          try {\n            const response = await axios.post('http://localhost:8000/together/', `prompt=${prompt_text}`, {\n              headers: {\n                'Content-Type': 'application/x-www-form-urlencoded'\n              }\n            });\n            this.aiResponse_1 = response.data.response;\n            this.contentRowStyle.height = 'auto';\n          } catch (error) {\n            console.error(\"There was an error fetching the AI response:\", error);\n            // Handle error (e.g., show error message)\n          } finally {\n            this.loading_1 = false; // Reset loading state once the request is complete\n          }\n        }\n      }\n    }\n  }\n};","map":{"version":3,"names":["axios","name","data","modelName","prompt_1","prompt_2","aiResponse_1","aiResponse_2","loading_1","loading_2","prompting_type","textareaStyle","height","openai_isActive","together_isActive","ex01_isActive","ex02_isActive","contentRowStyle","promptType_01","promptType_02","methods","setModel","ex01_setText","ex02_setText","getAIResponse","prompt_text","prompt_type","response","post","headers","error","console"],"sources":["/home/omid/Jobs/Wissenschaftliche*r Mitarbeiter*in im Bereich KI-Strategie/Prompt Engineering Toolkit/frontend/src/App.vue"],"sourcesContent":["<template>\n  <div class=\"container-fluid text-center\">\n    <div class=\"row\">\n      <div class=\"col-2\" style=\"background-color: black;\">\n        <div class=\"row left_elements\">\n          <div class=\"alert alert-success\" style=\"font-weight: bold;\" role=\"alert\">\n            Select an Example:\n          </div>\n        </div>\n        <div class=\"row left_elements\">\n          <button type=\"button\" class=\"btn btn-secondary left-btns\" \n            :class=\"{'btn-success': ex01_isActive}\" @click=\"ex01_setText\">\n            Example 01: Quetion Answering (Zero-Shot vs Few-Shot)\n          </button>\n        </div>\n        <div class=\"row left_elements\">\n          <button type=\"button\" class=\"btn btn-secondary left-btns\" \n            :class=\"{'btn-success': ex02_isActive}\" @click=\"ex02_setText\">\n            Example 02: Quetion Answering (Few-Shot vs Few-Shot Chain of Thought)\n          </button>\n        </div>\n      </div>\n      <div class=\"col-10\" style=\"background-color: #343541;\">\n        <div class=\"row left_elements\">\n          <div class=\"col-8\" style=\"float: left;\">\n            <div class=\"alert alert-success\" style=\"font-weight: bold;\" role=\"alert\">\n              Model: {{ modelName }}\n            </div>\n          </div>\n          <div class=\"col-2\">\n            <button type=\"button\" class=\"btn btn-secondary\" :class=\"{'btn-success': openai_isActive}\" @click=\"setModel('GPT 3.5 Turbo')\">OpenAI API</button>\n          </div>\n          <div class=\"col-2\">\n            <button type=\"button\" class=\"btn btn-secondary\" :class=\"{'btn-success': together_isActive}\" @click=\"setModel('llama-2-70b-chat')\">Together API</button>\n          </div>\n          \n        </div>\n        <div class=\"row\" id=\"ex01-question-answering\" :style=\"contentRowStyle\">\n          <div class=\"col-6\">\n            <div class=\"row\">\n              <div class=\"col-12\">\n                <div class=\"alert alert-primary\" role=\"alert\">\n                  {{promptType_01}}\n                </div>\n              </div>\n            </div>\n            <div class=\"row\">\n              <div class=\"col-12\">\n                <textarea v-model=\"prompt_1\" placeholder=\"Enter your prompt\" style=\"height: 200px;\"></textarea>\n              </div>\n            </div>\n            <div class=\"row\">\n              <div class=\"col-12\">\n                <button class=\"btn btn-primary\" @click=\"getAIResponse(this.prompt_1, 'zero_shot', this.modelName)\" :disabled=\"loading\">\n                  <span v-if=\"loading_1\" class=\"spinner-border spinner-border-sm\" role=\"status\" aria-hidden=\"true\"></span>\n                  <span v-else>Submit</span>\n                </button>\n              </div>\n            </div>\n            <div class=\"row\">\n              <div class=\"col-12\">\n                <p style=\"color: white; height: auto; text-align: left;\">Response: {{ aiResponse_1 }}</p>\n              </div>\n            </div>\n          </div>\n          <div class=\"col-6\">\n            <div class=\"row\">\n              <div class=\"col-12\">\n                <div class=\"alert alert-primary\" role=\"alert\">\n                  {{promptType_02}}\n                </div>\n              </div>\n            </div>\n            <div class=\"row\">\n              <div class=\"col-12\">\n                <textarea v-model=\"prompt_2\" placeholder=\"Enter your prompt\" :style=\"textareaStyle\"></textarea>\n              </div>\n            </div>\n            <div class=\"row\">\n              <div class=\"col-12\">\n                <button class=\"btn btn-primary\" @click=\"getAIResponse(this.prompt_2, 'few_shot', this.modelName)\" :disabled=\"loading\">\n                  <span v-if=\"loading_2\" class=\"spinner-border spinner-border-sm\" role=\"status\" aria-hidden=\"true\"></span>\n                  <span v-else>Submit</span>\n                </button>\n              </div>\n            </div>\n            <div class=\"row\">\n              <div class=\"col-12\">\n                <p style=\"color: white; height: auto; text-align: left;\">Response: {{ aiResponse_2 }}</p>\n              </div>\n            </div>\n          </div>\n          \n        </div>\n      </div>\n    </div>\n    \n  </div>\n</template>\n\n<script>\nimport axios from 'axios';\n\nexport default {\n  name: 'AIPrompt',\n  data() {\n    return {\n      modelName: 'GPT 3.5 Turbo',\n      prompt_1: '',\n      prompt_2: '',\n      aiResponse_1: '',\n      aiResponse_2: '',\n      loading_1: false,\n      loading_2: false,\n      prompting_type: \"\",\n      textareaStyle: {\n        height: '200px',\n      },\n      openai_isActive: true,\n      together_isActive : false,\n      ex01_isActive: false,\n      ex02_isActive : false,\n      contentRowStyle: {\n        height: '700px',\n      },\n      promptType_01: '',\n      promptType_02: '',\n    }\n  },\n  methods: {\n    setModel(name) {\n      this.modelName = name;\n      if (name == 'GPT 3.5 Turbo') {\n        this.openai_isActive = !this.openai_isActive;\n        this.together_isActive = false;\n      }\n      if (name == 'llama-2-70b-chat') {\n        this.openai_isActive = false;\n        this.together_isActive = !this.together_isActive;\n      }\n      \n      \n    },\n    ex01_setText() {\n      this.promptType_01 = 'Zero-Shot Prompting'\n      this.promptType_02 = 'Few-Shot Prompting'\n      this.ex01_isActive = !this.ex01_isActive\n      this.ex02_isActive = false\n      this.prompt_1 = \"What are the recommended treatments for hypertension?\";\n      this.prompt_2 = \"Question 1: What is the primary function of the heart in the human body?\\n\" +\n                      \"Answer 1: The primary function of the heart is to pump blood throughout \" +\n                      \"the body, delivering oxygen and nutrients to tissues and removing carbon \" +\n                      \"dioxide and other wastes.\\n\\n\" +\n                      \"Question 2: Can you explain what causes the common cold?\\n\" +\n                      \"Answer 2: The common cold is primarily caused by rhinoviruses. \" +\n                      \"It spreads through airborne droplets when an infected person coughs \" +\n                      \"or sneezes, or through direct contact with infected surfaces.\\n\\n\" +\n                      \"Question 3: What are the typical symptoms of diabetes?\\n\" +\n                      \"Answer 3: Typical symptoms of diabetes include increased thirst, \" +\n                      \"frequent urination, hunger, fatigue, and blurred vision. \" +\n                      \"In some cases, there may also be weight loss despite an increase \" +\n                      \"in appetite.\\n\\n\" +\n                      \"New Question: What are the recommended treatments for hypertension?\"; \n      this.textareaStyle.height = \"400px\";\n                      \n    },\n    ex02_setText() {\n      this.promptType_01 = 'Few-Shot Prompting'\n      this.promptType_02 = 'Few-Shot-CoT Prompting'\n      this.ex01_isActive = false\n      this.ex02_isActive = !this.ex02_isActive\n      this.prompt_1 = \"Q: Roger has 5 tennis balls. He buys 2 more cans of tennis \" +\n                      \"balls. Each can has 3 tennis balls. How many tennis balls does \" +\n                      \"he have now?\\n\" +\n                      \"A: The answer is 11.\\n\\n\" +\n                      \"Q: A juggler can juggle 16 balls. Half of the balls are golf balls, \" +\n                      \"and half of the golf balls are blue. How many blue golf balls are there?\\n\" +\n                      \"A:\";\n      this.prompt_2 = \"Q: Roger has 5 tennis balls. He buys 2 more cans of tennis \" +\n                      \"balls. Each can has 3 tennis balls. How many tennis balls does \" +\n                      \"he have now?\\n\" +\n                      \"A: Roger started with 5 balls. 2 cans of 3 tennis balls each is 6 \" +\n                      \"tennis balls. 5 + 6 = 11. The answer is 11.\\n\\n\" +\n                      \"Q: A juggler can juggle 16 balls. Half of the balls are golf balls, \" +\n                      \"and half of the golf balls are blue. How many blue golf balls are there?\\n\"\n                      \"A:\"; \n      this.textareaStyle.height = \"200px\";\n                      \n    },\n    async getAIResponse(prompt_text, prompt_type, modelName) {\n      if (modelName == 'GPT 3.5 Turbo') {\n        if (prompt_type == \"few_shot\"){\n          this.loading_2 = true; // Set loading to true when the request starts\n          try {\n            const response = await axios.post('http://localhost:8000/openai/', `prompt=${prompt_text}`, {\n              headers: {\n                'Content-Type': 'application/x-www-form-urlencoded',\n              }\n            });\n            this.aiResponse_2 = response.data.response;\n            this.contentRowStyle.height = 'auto';\n          } catch (error) {\n            console.error(\"There was an error fetching the AI response:\", error);\n            // Handle error (e.g., show error message)\n          } finally {\n            this.loading_2 = false; // Reset loading state once the request is complete\n          }\n        }\n        if (prompt_type == \"zero_shot\"){\n          this.loading_1 = true; // Set loading to true when the request starts\n          try {\n            const response = await axios.post('http://localhost:8000/openai/', `prompt=${prompt_text}`, {\n              headers: {\n                'Content-Type': 'application/x-www-form-urlencoded',\n              }\n            });\n            this.aiResponse_1 = response.data.response;\n            this.contentRowStyle.height = 'auto';\n          } catch (error) {\n            console.error(\"There was an error fetching the AI response:\", error);\n            // Handle error (e.g., show error message)\n          } finally {\n            this.loading_1 = false; // Reset loading state once the request is complete\n          }\n        }\n      }\n      else if (modelName == 'llama-2-70b-chat') \n      {\n        if (prompt_type == \"few_shot\"){\n          this.loading_2 = true; // Set loading to true when the request starts\n          try {\n            const response = await axios.post('http://localhost:8000/together/', `prompt=${prompt_text}`, {\n              headers: {\n                'Content-Type': 'application/x-www-form-urlencoded',\n              }\n            });\n            this.aiResponse_2 = response.data.response;\n            this.contentRowStyle.height = 'auto';\n          } catch (error) {\n            console.error(\"There was an error fetching the AI response:\", error);\n            // Handle error (e.g., show error message)\n          } finally {\n            this.loading_2 = false; // Reset loading state once the request is complete\n          }\n        }\n        if (prompt_type == \"zero_shot\"){\n          this.loading_1 = true; // Set loading to true when the request starts\n          try {\n            const response = await axios.post('http://localhost:8000/together/', `prompt=${prompt_text}`, {\n              headers: {\n                'Content-Type': 'application/x-www-form-urlencoded',\n              }\n            });\n            this.aiResponse_1 = response.data.response;\n            this.contentRowStyle.height = 'auto';\n          } catch (error) {\n            console.error(\"There was an error fetching the AI response:\", error);\n            // Handle error (e.g., show error message)\n          } finally {\n            this.loading_1 = false; // Reset loading state once the request is complete\n          }\n        }\n      }\n    }\n  }\n}\n</script>\n\n\n<style>\n#app {\n  font-family: Avenir, Helvetica, Arial, sans-serif;\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n  text-align: center;\n  color: #2c3e50;\n  /* margin-top: 60px; */\n  /* background-color: rgb(48, 48, 48); */\n}\nhtml, body {\n  height: 100%;\n  margin: 0; /* Remove default margin */\n}\n.row .left_elements {\n  padding: 10px;\n}\n.left_elements .left-btns {\n  padding: 30px;\n  font-weight: bold;\n}\ntextarea {\n  width: 100%;\n  margin-bottom: 20px !important;\n}\n#ex01-question-answering {\n  display: show;\n}\n\n</style>\n"],"mappings":"AAqGA,OAAOA,KAAI,MAAO,OAAO;AAEzB,eAAe;EACbC,IAAI,EAAE,UAAU;EAChBC,IAAIA,CAAA,EAAG;IACL,OAAO;MACLC,SAAS,EAAE,eAAe;MAC1BC,QAAQ,EAAE,EAAE;MACZC,QAAQ,EAAE,EAAE;MACZC,YAAY,EAAE,EAAE;MAChBC,YAAY,EAAE,EAAE;MAChBC,SAAS,EAAE,KAAK;MAChBC,SAAS,EAAE,KAAK;MAChBC,cAAc,EAAE,EAAE;MAClBC,aAAa,EAAE;QACbC,MAAM,EAAE;MACV,CAAC;MACDC,eAAe,EAAE,IAAI;MACrBC,iBAAgB,EAAI,KAAK;MACzBC,aAAa,EAAE,KAAK;MACpBC,aAAY,EAAI,KAAK;MACrBC,eAAe,EAAE;QACfL,MAAM,EAAE;MACV,CAAC;MACDM,aAAa,EAAE,EAAE;MACjBC,aAAa,EAAE;IACjB;EACF,CAAC;EACDC,OAAO,EAAE;IACPC,QAAQA,CAACpB,IAAI,EAAE;MACb,IAAI,CAACE,SAAQ,GAAIF,IAAI;MACrB,IAAIA,IAAG,IAAK,eAAe,EAAE;QAC3B,IAAI,CAACY,eAAc,GAAI,CAAC,IAAI,CAACA,eAAe;QAC5C,IAAI,CAACC,iBAAgB,GAAI,KAAK;MAChC;MACA,IAAIb,IAAG,IAAK,kBAAkB,EAAE;QAC9B,IAAI,CAACY,eAAc,GAAI,KAAK;QAC5B,IAAI,CAACC,iBAAgB,GAAI,CAAC,IAAI,CAACA,iBAAiB;MAClD;IAGF,CAAC;IACDQ,YAAYA,CAAA,EAAG;MACb,IAAI,CAACJ,aAAY,GAAI,qBAAoB;MACzC,IAAI,CAACC,aAAY,GAAI,oBAAmB;MACxC,IAAI,CAACJ,aAAY,GAAI,CAAC,IAAI,CAACA,aAAY;MACvC,IAAI,CAACC,aAAY,GAAI,KAAI;MACzB,IAAI,CAACZ,QAAO,GAAI,uDAAuD;MACvE,IAAI,CAACC,QAAO,GAAI,4EAA2E,GAC3E,0EAAyE,GACzE,2EAA0E,GAC1E,+BAA8B,GAC9B,4DAA2D,GAC3D,iEAAgE,GAChE,sEAAqE,GACrE,mEAAkE,GAClE,0DAAyD,GACzD,mEAAkE,GAClE,2DAA0D,GAC1D,mEAAkE,GAClE,kBAAiB,GACjB,qEAAqE;MACrF,IAAI,CAACM,aAAa,CAACC,MAAK,GAAI,OAAO;IAErC,CAAC;IACDW,YAAYA,CAAA,EAAG;MACb,IAAI,CAACL,aAAY,GAAI,oBAAmB;MACxC,IAAI,CAACC,aAAY,GAAI,wBAAuB;MAC5C,IAAI,CAACJ,aAAY,GAAI,KAAI;MACzB,IAAI,CAACC,aAAY,GAAI,CAAC,IAAI,CAACA,aAAY;MACvC,IAAI,CAACZ,QAAO,GAAI,6DAA4D,GAC5D,iEAAgE,GAChE,gBAAe,GACf,0BAAyB,GACzB,sEAAqE,GACrE,4EAA2E,GAC3E,IAAI;MACpB,IAAI,CAACC,QAAO,GAAI,6DAA4D,GAC5D,iEAAgE,GAChE,gBAAe,GACf,oEAAmE,GACnE,iDAAgD,GAChD,sEAAqE,GACrE,4EAA2E;MAC3E,IAAI;MACpB,IAAI,CAACM,aAAa,CAACC,MAAK,GAAI,OAAO;IAErC,CAAC;IACD,MAAMY,aAAaA,CAACC,WAAW,EAAEC,WAAW,EAAEvB,SAAS,EAAE;MACvD,IAAIA,SAAQ,IAAK,eAAe,EAAE;QAChC,IAAIuB,WAAU,IAAK,UAAU,EAAC;UAC5B,IAAI,CAACjB,SAAQ,GAAI,IAAI,EAAE;UACvB,IAAI;YACF,MAAMkB,QAAO,GAAI,MAAM3B,KAAK,CAAC4B,IAAI,CAAC,+BAA+B,EAAG,UAASH,WAAY,EAAC,EAAE;cAC1FI,OAAO,EAAE;gBACP,cAAc,EAAE;cAClB;YACF,CAAC,CAAC;YACF,IAAI,CAACtB,YAAW,GAAIoB,QAAQ,CAACzB,IAAI,CAACyB,QAAQ;YAC1C,IAAI,CAACV,eAAe,CAACL,MAAK,GAAI,MAAM;UACtC,EAAE,OAAOkB,KAAK,EAAE;YACdC,OAAO,CAACD,KAAK,CAAC,8CAA8C,EAAEA,KAAK,CAAC;YACpE;UACF,UAAU;YACR,IAAI,CAACrB,SAAQ,GAAI,KAAK,EAAE;UAC1B;QACF;QACA,IAAIiB,WAAU,IAAK,WAAW,EAAC;UAC7B,IAAI,CAAClB,SAAQ,GAAI,IAAI,EAAE;UACvB,IAAI;YACF,MAAMmB,QAAO,GAAI,MAAM3B,KAAK,CAAC4B,IAAI,CAAC,+BAA+B,EAAG,UAASH,WAAY,EAAC,EAAE;cAC1FI,OAAO,EAAE;gBACP,cAAc,EAAE;cAClB;YACF,CAAC,CAAC;YACF,IAAI,CAACvB,YAAW,GAAIqB,QAAQ,CAACzB,IAAI,CAACyB,QAAQ;YAC1C,IAAI,CAACV,eAAe,CAACL,MAAK,GAAI,MAAM;UACtC,EAAE,OAAOkB,KAAK,EAAE;YACdC,OAAO,CAACD,KAAK,CAAC,8CAA8C,EAAEA,KAAK,CAAC;YACpE;UACF,UAAU;YACR,IAAI,CAACtB,SAAQ,GAAI,KAAK,EAAE;UAC1B;QACF;MACF,OACK,IAAIL,SAAQ,IAAK,kBAAkB,EACxC;QACE,IAAIuB,WAAU,IAAK,UAAU,EAAC;UAC5B,IAAI,CAACjB,SAAQ,GAAI,IAAI,EAAE;UACvB,IAAI;YACF,MAAMkB,QAAO,GAAI,MAAM3B,KAAK,CAAC4B,IAAI,CAAC,iCAAiC,EAAG,UAASH,WAAY,EAAC,EAAE;cAC5FI,OAAO,EAAE;gBACP,cAAc,EAAE;cAClB;YACF,CAAC,CAAC;YACF,IAAI,CAACtB,YAAW,GAAIoB,QAAQ,CAACzB,IAAI,CAACyB,QAAQ;YAC1C,IAAI,CAACV,eAAe,CAACL,MAAK,GAAI,MAAM;UACtC,EAAE,OAAOkB,KAAK,EAAE;YACdC,OAAO,CAACD,KAAK,CAAC,8CAA8C,EAAEA,KAAK,CAAC;YACpE;UACF,UAAU;YACR,IAAI,CAACrB,SAAQ,GAAI,KAAK,EAAE;UAC1B;QACF;QACA,IAAIiB,WAAU,IAAK,WAAW,EAAC;UAC7B,IAAI,CAAClB,SAAQ,GAAI,IAAI,EAAE;UACvB,IAAI;YACF,MAAMmB,QAAO,GAAI,MAAM3B,KAAK,CAAC4B,IAAI,CAAC,iCAAiC,EAAG,UAASH,WAAY,EAAC,EAAE;cAC5FI,OAAO,EAAE;gBACP,cAAc,EAAE;cAClB;YACF,CAAC,CAAC;YACF,IAAI,CAACvB,YAAW,GAAIqB,QAAQ,CAACzB,IAAI,CAACyB,QAAQ;YAC1C,IAAI,CAACV,eAAe,CAACL,MAAK,GAAI,MAAM;UACtC,EAAE,OAAOkB,KAAK,EAAE;YACdC,OAAO,CAACD,KAAK,CAAC,8CAA8C,EAAEA,KAAK,CAAC;YACpE;UACF,UAAU;YACR,IAAI,CAACtB,SAAQ,GAAI,KAAK,EAAE;UAC1B;QACF;MACF;IACF;EACF;AACF"},"metadata":{},"sourceType":"module","externalDependencies":[]}